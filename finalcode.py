# -*- coding: utf-8 -*-
"""Copy of finalCODE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SKs0Cs5qQFZZld-APJsJE1KGXydWJIHZ
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error
import seaborn as sns

data = pd.read_csv('/content/sample_data/railwaysDAta.csv')

print(data.head())

feature_columns = ['GENDER', 'AGE', 'AGE RANGE']
target_column = 'NATURE OF INJURIES'

X_cls = data[feature_columns]
y_cls = data[target_column]

for col in X_cls.columns:
    if X_cls[col].dtype == 'object':
        # Convert categorical features to numeric using one-hot encoding
        X_cls = pd.get_dummies(X_cls, columns=[col], drop_first=True)

X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)

classifier_model = RandomForestClassifier(random_state=42)
classifier_model.fit(X_cls_train, y_cls_train)

y_cls_pred = classifier_model.predict(X_cls_test)

sns.heatmap(confusion_matrix(y_cls_test, y_cls_pred), annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - Classification Model')
plt.show()

classification_accuracy = accuracy_score(y_cls_test, y_cls_pred)
print(f'Classification Accuracy: {classification_accuracy}')
print('Classification Report:')
print(classification_report(y_cls_test, y_cls_pred))

feature_column_reg = 'AGE'
target_column_reg = 'NATURE OF INJURIES'

if X_cls[feature_column_reg].dtype == 'object':
    # Convert the categorical feature to numeric using one-hot encoding
    X_reg = pd.get_dummies(X_cls[[feature_column_reg]], drop_first=True)
else:
    X_reg = X_cls[[feature_column_reg]]

X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_cls, test_size=0.2, random_state=42)

regression_model = LogisticRegression()
regression_model.fit(X_reg_train, y_reg_train)

y_reg_pred = regression_model.predict(X_reg_test)

plt.scatter(X_reg_test, y_reg_test, label='Actual Data')
plt.plot(X_reg_test, y_reg_pred, 'r-', label='Regression Line')
plt.xlabel(feature_column_reg)
plt.ylabel(target_column_reg)
plt.legend()
plt.title('Regression Model')
plt.show()

regression_accuracy = accuracy_score(y_reg_test, y_reg_pred)
print(f'Regression Accuracy: {regression_accuracy}')

from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

if data[feature_column_reg].dtype == 'object':
    # Convert the categorical feature to numeric using one-hot encoding
    X_reg = pd.get_dummies(data[[feature_column_reg]], drop_first=True)
else:
    X_reg = data[[feature_column_reg]]

data['NATURE OF INJURIES'] = pd.Categorical(data['NATURE OF INJURIES']).codes

X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, data[target_column_reg], test_size=0.2, random_state=42)

dt_regressor_model = DecisionTreeRegressor(random_state=42)
dt_regressor_model.fit(X_reg_train, y_reg_train)

y_dt_reg_pred = dt_regressor_model.predict(X_reg_test)

plt.scatter(X_reg_test, y_reg_test, label='Actual Data')
plt.plot(X_reg_test, y_dt_reg_pred, 'r-', label='Regression Line')
plt.xlabel(feature_column_reg)
plt.ylabel(target_column_reg)
plt.legend()
plt.title('Decision Tree Regressor')
plt.show()

